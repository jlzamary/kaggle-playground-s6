# Added from Co-lab Notebook

# -*- coding: utf-8 -*-
"""playground_s6e1_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mkq8mVBSA4EzS1rwxOzRQd4gs1U9twfa

# Link Google Drive
"""

"""
from google.colab import drive
drive.mount('/content/drive')

! mkdir -p ~/.kaggle

! cp '/content/drive/MyDrive/Colab Notebooks/kaggle_API_key/kaggle.json' ~/.kaggle/kaggle.json

! chmod 600 ~/.kaggle/kaggle.json

### Import Playground Series Data

! kaggle competitions download -c playground-series-s6e1

! unzip playground-series-s6e1.zip
"""

"""### Import Libraries"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Import Machine Learning Libraries
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder,LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import root_mean_squared_error

"""### Dataframe Creation and Exploration"""

train_df = pd.read_csv('/content/train.csv')
test_df = pd.read_csv('/content/test.csv')

# Explore the data
train_df.head()

# Basic data prep
print('Data Shape: \n', train_df.shape)
print('\n Data Types: \n', train_df.dtypes)
print('\n Missing Values: \n', train_df.isnull().sum())

"""### Basic feature encoding"""

# Create a copy to avoid modifying original
df_encoded = train_df.copy()

# Binary encoding
df_encoded['internet_access'] = df_encoded['internet_access'].map({'no': 0, 'yes': 1})

# Ordinal encoding
ordinal_mappings = {
    'sleep_quality': {'poor': 0, 'average': 1, 'good': 2},
    'facility_rating': {'low': 0, 'medium': 1, 'high': 2},
    'exam_difficulty': {'easy': 0, 'moderate': 1, 'hard': 2}
}

for col, mapping in ordinal_mappings.items():
    df_encoded[col] = df_encoded[col].map(mapping)

# One-hot encoding
df_encoded = pd.get_dummies(df_encoded,
                            columns=['course', 'study_method', 'gender'],
                            dtype = int,      # Binary
                            drop_first=True)  # Avoid multicollinearity

# Encoded DataFrame
df_encoded.head()

"""### View Correlation"""

corr = df_encoded.corr(numeric_only=True)

plt.figure(figsize=(12,10))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)

"""### Prepare Data and Scale Features"""

# Separate features and target
X = df_encoded.drop(['id', 'exam_score'], axis=1)
y = df_encoded['exam_score']

# Then split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Train Amount: \n {len(X_train)}")
print(f"\n Test Amount: \n {len(X_test)}")

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""### XGBoost Model Params"""

# XGBoost model
model = xgb.XGBRegressor(
    n_estimators=250,
    learning_rate=0.1,
    max_depth=7,
    subsample=0.8,
    colsample_bytree=0.8,
    reg_alpha=0.5,
    reg_lambda=1,
    random_state=42,
    objective='reg:squarederror',
    eval_metric='rmse'
)

# Fit the model first
model.fit(X_train_scaled, y_train)

# Generate predictions
y_pred_train = model.predict(X_train_scaled)
y_pred_test = model.predict(X_test_scaled)

# Calculate RMSE
train_rmse = root_mean_squared_error(y_train, y_pred_train)
test_rmse = root_mean_squared_error(y_test, y_pred_test)

print(f"Training RMSE: {train_rmse:.2f}")
print(f"Test RMSE: {test_rmse:.2f}")

"""### Make Predictions on Test Data"""

# Create a copy to avoid modifying original
test_encoded = test_df.copy()

# Binary encoding
test_encoded['internet_access'] = test_encoded['internet_access'].map({'no': 0, 'yes': 1})

# Ordinal encoding
ordinal_mappings = {
    'sleep_quality': {'poor': 0, 'average': 1, 'good': 2},
    'facility_rating': {'low': 0, 'medium': 1, 'high': 2},
    'exam_difficulty': {'easy': 0, 'moderate': 1, 'hard': 2}
}

for col, mapping in ordinal_mappings.items():
    test_encoded[col] = test_encoded[col].map(mapping)

# One-hot encoding
test_encoded = pd.get_dummies(test_encoded,
                            columns=['course', 'study_method', 'gender'],
                            dtype = int,      # Binary
                            drop_first=True)  # Avoid multicollinearity

# Prepare for prediction
test_ids = test_encoded['id']
X_test_kaggle = test_encoded.drop(['id'], axis=1)

# Scale and predict
X_test_kaggle_scaled = scaler.transform(X_test_kaggle)
predictions = model.predict(X_test_kaggle_scaled)

# Create submission
submission = pd.DataFrame({
    'id': test_ids,
    'exam_score': predictions
})

submission.to_csv('submission_3.csv', index=False)
print(f"Submission created with {len(predictions)} predictions")
submission.head()